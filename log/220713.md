## 220713

<br>

## 오후 12시 - 1시

<br>

1. 데이터셋 일반화 규격 수정시 고려사항 정리
- 현재는 MathQA 에 최적화되어 있음.
- 하지만 SVAMP 를 적용하게 되면, 기존 함수 순서를 변경할 필요가 있음.
- 우선 순서가 specific_Dataset, problem_processing, solution_processing 순서로 이뤄져 있음.
- specific_Dataset: 가장 먼저라서 좋다. 하지만 뒤에 processing 의 규격을 맞추려면 여기서 많은 게 이뤄져야 한다.
- 예시1: MathQA 는 question 에 숫자뿐이라서 problem_processing 에서 숫자를 일반화한다. 하지만 SVAMP 는 train 에서 number0 라는 양식을 사용한다.
- 예시2: MathQA 는 linear formula 에서 이미 전위표기법, 숫자 일반화, 식 값 재활용(#0, #1) 등이 이뤄져 있다. 하지만 SVAMP 에서는 train 은 재활용빼고는 다 되어 있으나, valid 는 중위 표기법, 숫자값 그대로이라서 모든 전처리를 거쳐야 한다. 그런데 숫자값을 일반화하려면, 문제에서 [N0], [N1] 이 누구인지 알아야 하므로, 결국 specific 단계에서 problem_processing 에서 해야 하는 과정을 미리 거쳐야 한다.

결론: 다른 데이터셋이 어떨지 몰라서 일단 냅뒀으나, 지금 과정을 수정할 필요가 있어 보인다.

<br>

2. valid_loss
- 보통 valid loss 가 다시 오르면, overfitting 되었다고 판단해서 학습을 멈추는 것으로 알고 있음.
- 그런데, valid_loss 는 구하지 않고 그대신 valid_acc 가 일정 수준에서 머물면, 학습을 종료하고자 함.
- 사실 이 부분에서 좀 더 이야기가 필요할 것 같음.

<br>

3. 간단한 실험
- mBERT-LSTM: 기본 bert 로 변경해서 SVAMP, MathQA 에 적용해봐도 성능이 동일함.
- dropout 적용

<br>

## 오후 1시 - 3시

<br>

1. 현황 공유
- SVAMP 양식 관련 합의: 멘토님이 작성하신 양식에 대해 좀 더 자세히 이해하는 계기가 되었음.
- valid_loss: 생성 모델, 적어도 MWP 분야에 공개된 모델들은 valid_loss 를 계산하지 않고, 최고 성능일 때를 기준으로 함. 성능 변화가 저조한 경우에 early_stop 을 진행한다고 함.
- 데이터 표현식 작성 관련 계획: 우선 추상적으로라도 달기로 함.
- 작년 모델 개선 관련 자료 공유
- 모델 개선 방향 아이디어 제시
- 브런치 병합: 따로 작업한 걸 금요일(22.07.15)에 합치기로 함.

## 오후 3시 20분 - 3시 50분

1. Tokenizer max_len 연산 오류 발견
- EOS, BOS 개수가 빠져서 여태껏 결과가 이상하게 측정되었음.
- 재실험해서 성능을 확인하기로 함.

## 오후 4시 - 6시

1. 논문 세미나
- MWP 분야에서 차용해볼만한 것은 constastive learning 이다. STS 등 도 활용해볼 만한지 고민해봐도 좋을 것 같다.

<br>

## 오후 12시 - 오전 1시

1. remote VScode Error
- 잘 열리던 docker 가 열리지 않는다. vscode 자동 업데이트로 인해서 그럴 수 있다고 한다. 그래서 일단 다운그레이드 해보기로 함.

